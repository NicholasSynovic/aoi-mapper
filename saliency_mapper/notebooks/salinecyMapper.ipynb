{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJD_FpLestp"
      },
      "source": [
        "# Saliency Mapper\n",
        "\n",
        "> A tool to generate the saliency maps of images using a variety of techniques\n",
        "\n",
        "Code was written by Nicholas M. Synovic, Oscar Yanek, and Rohan Sethi\n",
        "\n",
        "## Optimal Performance\n",
        "\n",
        "For optimal performance, in the *Runtime* tab of Google Collab, click *Change runtime type*, then choose **GPU** from the *Hardware Accelerator* dropdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUPl1Y3afhjX"
      },
      "source": [
        "## Upgrade Python `pip` Tool\n",
        "\n",
        "Upgrade the Python `pip` tool to the latest version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTjj0EYGfmxm",
        "outputId": "dfeada01-f30e-4604-970a-b3a9d7576a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\oyane_5ab4y9h\\appdata\\roaming\\python\\python39\\site-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Using cached pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "  Rolling back uninstall of pip\n",
            "  Moving to c:\\users\\oyane_5ab4y9h\\appdata\\roaming\\python\\python39\\scripts\\\n",
            "   from C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\~cripts\n",
            "  Moving to c:\\users\\oyane_5ab4y9h\\appdata\\roaming\\python\\python39\\site-packages\\pip-22.0.4.dist-info\\\n",
            "   from C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\~ip-22.0.4.dist-info\n",
            "  Moving to c:\\users\\oyane_5ab4y9h\\appdata\\roaming\\python\\python39\\site-packages\\pip\\\n",
            "   from C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\~ip\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: No metadata found in c:\\users\\oyane_5ab4y9h\\appdata\\roaming\\python\\python39\\site-packages\n",
            "ERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 205, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\commands\\install.py\", line 405, in run\n",
            "    installed = install_given_reqs(\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\req\\__init__.py\", line 73, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\req\\req_install.py\", line 769, in install\n",
            "    install_wheel(\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 729, in install_wheel\n",
            "    _install_wheel(\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 646, in _install_wheel\n",
            "    generated_console_scripts = maker.make_multiple(scripts_to_generate)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\distlib\\scripts.py\", line 428, in make_multiple\n",
            "    filenames.extend(self.make(specification, options))\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 427, in make\n",
            "    return super().make(specification, options)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\distlib\\scripts.py\", line 417, in make\n",
            "    self._make_script(entry, filenames, options=options)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\distlib\\scripts.py\", line 317, in _make_script\n",
            "    self._write_script(scriptnames, shebang, script, filenames, ext)\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\distlib\\scripts.py\", line 247, in _write_script\n",
            "    launcher = self._get_launcher('t')\n",
            "  File \"C:\\Users\\oyane_5ab4y9h\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\distlib\\scripts.py\", line 396, in _get_launcher\n",
            "    raise ValueError(msg)\n",
            "ValueError: Unable to find resource t64.exe in package pip._vendor.distlib\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\oyane_5ab4y9h\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbqWSZMQe_B_"
      },
      "source": [
        "## Install Python libaries via `pip`\n",
        "\n",
        "Installed libraries are:\n",
        "\n",
        "- opencv-contrib-python\n",
        "- torch\n",
        "- torchvision\n",
        "- pandas\n",
        "- progress\n",
        "- timm\n",
        "- ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXq-rWDCJd4w",
        "outputId": "78cea49b-95c8-4ca9-a64f-bbd29844412a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
            "Requirement already satisfied: torch in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (1.12.1)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement timeit (from versions: none)\n",
            "ERROR: No matching distribution found for timeit\n",
            "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\oyane_5ab4y9h\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: torchvision in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (0.13.1)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (0.12.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (1.3.4)\n",
            "Requirement already satisfied: progress in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (1.6)\n",
            "Requirement already satisfied: timm in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (0.6.11)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\oyane_5ab4y9h\\anaconda3\\lib\\site-packages (7.6.5)\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-contrib-python torch torchvision torchaudio pandas progress timm ipywidgets timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEpl7l6hKPX"
      },
      "source": [
        "## Import Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "E4vBBhvvfD_u"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from pathlib import PurePath\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "#from google.colab import drive\n",
        "from numpy import ndarray\n",
        "from progress.bar import Bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUjbgiZ9hVCQ"
      },
      "source": [
        "## Allow Data to be Loaded From Google Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkdMd79XhalG",
        "outputId": "ad372c16-91c4-4c23-bbf0-53f786604870"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQKDGcMOikM_"
      },
      "source": [
        "## Main Application\n",
        "\n",
        "Initialize variables for program scope "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "spectralSaliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
        "fineGrainSaliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
        "depth_DPTLarge: str = \"DPT_Large\"\n",
        "depth_DPTHybrid: str = \"DPT_Hybrid\"\n",
        "depth_MiDaSsmall: str = \"MiDaS_small\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Directory Reader\n",
        "\n",
        "when giving the program a dataset instead of singular image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def readDirectory(dir: str) -> list:\n",
        "    files: list = listdir(dir)\n",
        "    filepaths: list = [join(dir, f) for f in files]\n",
        "    return filepaths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EstimateDepth Main Logic\n",
        "\n",
        "Determines desired training model from the arguments. Uses loading bar to parse through imagePaths List, performs transformation on each image and outputs the result to a new folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimateDepth(imagePaths: list, modelType: str, outputFolder: str = \"data\") -> None:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", modelType)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    midas.to(device)\n",
        "    if modelType == \"DPT_Large\" or modelType == \"DPT_Hybrid\":\n",
        "        transform = midas_transforms.dpt_transform\n",
        "    else:\n",
        "        transform = midas_transforms.small_transform\n",
        "\n",
        "    with Bar(f\"Estimating depth with {modelType}...\", max=(len(imagePaths))) as bar:\n",
        "        imagePath: str\n",
        "        for imagePath in imagePaths:\n",
        "            imageName: str = (\n",
        "                PurePath(imagePath).with_suffix(\"\").name\n",
        "                + f'_{modelType.replace(\"_\", \"-\")}.jpg'\n",
        "            )\n",
        "            outputPath: str = join(outputFolder, imageName)\n",
        "\n",
        "            image: ndarray = cv2.imread(imagePath)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            input_batch = transform(image).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = midas(input_batch)\n",
        "\n",
        "                prediction = torch.nn.functional.interpolate(\n",
        "                    prediction.unsqueeze(1),\n",
        "                    size=image.shape[:2],\n",
        "                    mode=\"bicubic\",\n",
        "                    align_corners=False,\n",
        "                ).squeeze()\n",
        "\n",
        "            output = prediction.cpu().numpy()\n",
        "            cv2.imwrite(outputPath, output)\n",
        "            bar.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ComputeSpectralSaliency Main Logic\n",
        "\n",
        "Creates output folder and path, takes input imagePath and creates a saliency map for the image using the spectral residual approach. Starting from the principle of natural image statistics, this method simulate the behavior of pre-attentive visual search. The algorithm analyze the log spectrum of each image and obtain the spectral residual. Then transform the spectral residual to spatial domain to obtain the saliency map, which suggests the positions of proto-objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def computeSpectralSaliency(imagePath: str, outputFolder: str = \"data\") -> None:\n",
        "    imageName: str = PurePath(imagePath).with_suffix(\"\").name + \"_spectralResidual.jpg\"\n",
        "    outputPath: str = join(outputFolder, imageName)\n",
        "    image: ndarray = cv2.imread(imagePath)\n",
        "    (success, saliencyMap) = spectralSaliency.computeSaliency(image)\n",
        "    saliencyMap: ndarray = (saliencyMap * 255).astype(\"uint8\")\n",
        "    cv2.imwrite(outputPath, saliencyMap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ComputeFineGrainSaliency Main Logic\n",
        "\n",
        "Creates output folder and path, takes input imagePath and creates a saliency map for the image using the fine grained approach. This method calculates saliency based on center-surround differences. High resolution saliency maps are generated in real time by using integral images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def computeFineGrainSaliency(imagePath: str, outputFolder: str = \"data\") -> None:\n",
        "    imageName: str = PurePath(imagePath).with_suffix(\"\").name + \"_fineGrain.jpg\"\n",
        "    outputPath: str = join(outputFolder, imageName)\n",
        "    image: ndarray = cv2.imread(imagePath)\n",
        "    (success, saliencyMap) = fineGrainSaliency.computeSaliency(image)\n",
        "    saliencyMap: ndarray = (saliencyMap * 255).astype(\"uint8\")\n",
        "    cv2.imwrite(outputPath, saliencyMap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic writeImage function\n",
        "\n",
        "Writes an image to a desired path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def writeImage(image: ndarray, imagePath: str) -> None:\n",
        "    cv2.imwrite(imagePath, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Otsu Threshold Background Removal\n",
        "\n",
        "Blurs image to reduce noise. Bins the pixels between 1-5. Creates a single channel greyscale for thresholding. Performs Otsu Thresholding and extracts the background. Uses binary thershold to create an all white background. Converts black and white back into 3 channel greyscale. Performs Otsu thresholding and extracts the foreground. Uses TOZERO_INV to keep some detail of the foreground. Combines the background and foreground to make final image. returns final image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bgremove1(myimage):\n",
        " \n",
        "    myimage = cv2.GaussianBlur(myimage,(5,5), 0)\n",
        " \n",
        "    bins=numpy.array([0,51,102,153,204,255])\n",
        "    myimage[:,:,:] = numpy.digitize(myimage[:,:,:],bins,right=True)*51\n",
        " \n",
        "    myimage_grey = cv2.cvtColor(myimage, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "    ret,background = cv2.threshold(myimage_grey,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        " \n",
        "    background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)\n",
        " \n",
        "    ret,foreground = cv2.threshold(myimage_grey,0,255,cv2.THRESH_TOZERO_INV+cv2.THRESH_OTSU)  #Currently foreground is only a mask\n",
        "    foreground = cv2.bitwise_and(myimage,myimage, mask=foreground)  # Update foreground with bitwise_and to extract real foreground\n",
        " \n",
        "    finalimage = background+foreground\n",
        " \n",
        "    return finalimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Thresholding Background Removal\n",
        "\n",
        "First converts to greyscale. Performs truncate threshold to get baseline. Extracts binary threshold using the baseline for the background and foreground. Updates foreground with bitwise_and to extract real foreground. Converts black and white back into 3 channel greyscale. Combines the background and foreground to obtain our final image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bgremove2(myimage):\n",
        "\n",
        "    myimage_grey = cv2.cvtColor(myimage, cv2.COLOR_BGR2GRAY)\n",
        " \n",
        "    ret,baseline = cv2.threshold(myimage_grey,127,255,cv2.THRESH_TRUNC)\n",
        " \n",
        "    ret,background = cv2.threshold(baseline,126,255,cv2.THRESH_BINARY)\n",
        " \n",
        "    ret,foreground = cv2.threshold(baseline,126,255,cv2.THRESH_BINARY_INV)\n",
        " \n",
        "    foreground = cv2.bitwise_and(myimage,myimage, mask=foreground)  \n",
        "\n",
        "    background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)\n",
        " \n",
        "    finalimage = background+foreground\n",
        "    return finalimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hue Saturation Value\n",
        "\n",
        "Converts image from BGR to HSV. Takes saturation and removes any values that are less than half creating the saturation mask. Increases the brightness of the image and then mods by 255 . Extracts any value above 127 to be a part of the value mask. Combines the two masks into unified foreground. Casts back into 8-bit integer. Inverts foreground to get background in uint8. Converts background back into BGR. Applies foreground map to original image. Combines foreground and background.\n",
        "\n",
        "Documentation: https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bgremove3(myimage):\n",
        "\n",
        "    myimage_hsv = cv2.cvtColor(myimage, cv2.COLOR_BGR2HSV)\n",
        "     \n",
        "    s = myimage_hsv[:,:,1]\n",
        "    s = numpy.where(s < 127, 0, 1) \n",
        " \n",
        "    v = (myimage_hsv[:,:,2] + 127) % 255\n",
        "    v = numpy.where(v > 127, 1, 0)  \n",
        "\n",
        "    foreground = numpy.where(s+v > 0, 1, 0).astype(numpy.uint8)  \n",
        "\n",
        "    background = numpy.where(foreground==0,255,0).astype(numpy.uint8) \n",
        "    background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)  \n",
        "    foreground=cv2.bitwise_and(myimage,myimage,mask=foreground) \n",
        "    finalimage = background+foreground \n",
        "\n",
        "    return finalimage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combined Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oTH2X0mhhbz1",
        "outputId": "70cab19a-d784-4a94-d8c1-87dd16f1f0cc"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9032/4180835018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9032/4180835018.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mimagePath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimagePath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimagePaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mcomputeSpectralSaliency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mcomputeFineGrainSaliency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9032/3540457892.py\u001b[0m in \u001b[0;36mcomputeSpectralSaliency\u001b[1;34m(imagePath, outputFolder)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaliencyMap\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspectralSaliency\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeSaliency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msaliencyMap\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msaliencyMap\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"uint8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaliencyMap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
          ]
        }
      ],
      "source": [
        "\n",
        "def main() -> None:\n",
        "    # dirImage = input(\"image dir path is: \")\n",
        "    # dirOut = input(\"output image dir path is: \")\n",
        "    # imagePaths: list = readDirectory(dir=dirImage)\n",
        "    imagePaths: list = [\"test.jpg\"]\n",
        "    dirOut = \"data\"\n",
        "    with Bar(\n",
        "        \"Creating saliency maps of PascalVOC images...\", max=len(imagePaths)\n",
        "    ) as bar:\n",
        "        imagePath: str\n",
        "        for imagePath in imagePaths:\n",
        "            computeSpectralSaliency(imagePath)\n",
        "            computeFineGrainSaliency(imagePath)\n",
        "            bar.next()\n",
        "\n",
        "    imagePath: str = input(\"Enter path: \")\n",
        "    image: ndarray = cv2.imread(imagePath)\n",
        "    showimage(bgremove1(image))\n",
        "    showimage(bgremove2(image))\n",
        "    showimage(bgremove3(image))\n",
        "\n",
        "    estimateDepth(imagePaths, depth_DPTHybrid)\n",
        "    estimateDepth(imagePaths, depth_DPTLarge)\n",
        "    estimateDepth(imagePaths, depth_MiDaSsmall)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark Code\n",
        "\n",
        "Benchmark function that outputs to console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timeit import timeit\n",
        "\n",
        "accHW = input(\"Enter Accelerator type and test number: \")\n",
        "\n",
        "f=open(accHW+\".txt\")\n",
        "f.write(\n",
        "    'SpectralSaliency time: '+timeit.timeit(\"computeSpectralSaliency(imageTestPath)\", globals=globals())+\"/n\"+\n",
        "    'FineGrainSaliency time: '+timeit.timeit(\"computeFineGrainSaliency(imageTestPath)\", globals=globals())+\"/n\"+\n",
        "    'DPTHybrid time: '+timeit.timeit(\"computeSpectralSaliency(imageTestPath)\", globals=globals())+\"/n\"+\n",
        "    'DPTLarge time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_DPTLarge)\", globals=globals())+\"/n\"+\n",
        "    'MiDaSsmall time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_MiDaSsmall)\", globals=globals())+\"/n\"+\n",
        "    'DPTHybrid time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_DPTHybrid)\", globals=globals())+\"/n\"+\n",
        "    'bgremove1 time: '+timeit.timeit(\"bgremove1(imageTestPath)\",globals=globals())+\"/n\"+\n",
        "    'bgremove2 time: '+timeit.timeit(\"bgremove2(imageTestPath)\",globals=globals())+\"/n\"+\n",
        "    'bgremove3 time: '+timeit.timeit(\"bgremove3(imageTestPath)\",globals=globals())\n",
        ")\n",
        "f.close()\n",
        "\n",
        "imageTestPath: str = input(\"Enter path: \")\n",
        "imageTestPaths: list = [imageTestPath]\n",
        "print('SpectralSaliency time: '+timeit.timeit(\"computeSpectralSaliency(imageTestPath)\", globals=globals()))\n",
        "print('FineGrainSaliency time: '+timeit.timeit(\"computeFineGrainSaliency(imageTestPath)\", globals=globals()))\n",
        "print('DPTHybrid time: '+timeit.timeit(\"computeSpectralSaliency(imageTestPath)\", globals=globals()))\n",
        "print('DPTLarge time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_DPTLarge)\", globals=globals()))\n",
        "print('MiDaSsmall time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_MiDaSsmall)\", globals=globals()))\n",
        "print('DPTHybrid time: '+timeit.timeit(\"estimateDepth(imageTestPaths, depth_DPTHybrid)\", globals=globals()))\n",
        "print('bgremove1 time: '+timeit.timeit(\"bgremove1(imageTestPath)\",globals=globals()))\n",
        "print('bgremove2 time: '+timeit.timeit(\"bgremove2(imageTestPath)\",globals=globals()))\n",
        "print('bgremove3 time: '+timeit.timeit(\"bgremove3(imageTestPath)\",globals=globals()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "8dad799e74c173899b51d02c689b918710741a3d4b9f84c36d76825a0cf9e68c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Checker\n",
    "\n",
    "> A tool to check if the bounding boxes from the PascalVOC 2012 dataset aligns with the area of interest maps\n",
    "\n",
    "Code was written by Nicholas M. Synovic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upgrade Python `pip` tool\n",
    "\n",
    "Upgrade the Python `pip` tool to the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python libaries via `pip`\n",
    "\n",
    "Installed libraries are:\n",
    "\n",
    "- opencv-contrib-python\n",
    "- progress\n",
    "- pandas\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: progress in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (1.6)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Requirement already satisfied: numpy in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (1.23.4)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.5-py2.py3-none-any.whl (500 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.7/500.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/nicholas/.cache/pypoetry/virtualenvs/saliency-mapper-VKvJKC8t-py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.5.1 pytz-2022.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-contrib-python progress pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from pathlib import PurePath\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow Data to be Loaded From Google Drive\n",
    "\n",
    "If you wish to load data from Google Drive, uncomment the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Directory\n",
    "\n",
    "Function to read a directory and return a list of filepaths from that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDirectory(dir: str) -> list:\n",
    "    files: list = listdir(dir)\n",
    "    filepaths: list = [join(dir, f) for f in files]\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Depth with MiDaS\n",
    "\n",
    "Takes a file path to an image (`imagePath`) and an output folder path (default is `./data`; `outputFolder`) as input. A model type (`modelType`) is required as well.\n",
    "\n",
    "**NOTE**: `modelType` must be a compatible MiDaS model type. See [here](https://pytorch.org/hub/intelisl_midas_v2/) for supported model types.\n",
    "\n",
    "It then uses the approach outlined in [1, 2](#citations) to estimate the depth of an image.\n",
    "\n",
    "Area of interest maps are saved in `.jpg` format in the `outputFolder` with the following scheme:\n",
    "\n",
    "- `outputFolder`/FILENAME_MODELTYPE`.jpg`\n",
    "\n",
    "Where FILENAME is the original name of the file without the extension and MODELTYPE is the model type that was used for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateDepth(imagePaths: list, modelType: str, outputFolder: str = \"data\") -> None:\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", modelType)\n",
    "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    midas.to(device)\n",
    "    if modelType == \"DPT_Large\" or modelType == \"DPT_Hybrid\":\n",
    "        transform = midas_transforms.dpt_transform\n",
    "    else:\n",
    "        transform = midas_transforms.small_transform\n",
    "\n",
    "    with Bar(f\"Estimating depth with {modelType}...\", max=(len(imagePaths))) as bar:\n",
    "        imagePath: str\n",
    "        for imagePath in imagePaths:\n",
    "            imageName: str = (\n",
    "                PurePath(imagePath).with_suffix(\"\").name\n",
    "                + f'_{modelType.replace(\"_\", \"-\")}.jpg'\n",
    "            )\n",
    "            outputPath: str = join(outputFolder, imageName)\n",
    "\n",
    "            image: ndarray = cv2.imread(imagePath)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            input_batch = transform(image).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = midas(input_batch)\n",
    "\n",
    "                prediction = torch.nn.functional.interpolate(\n",
    "                    prediction.unsqueeze(1),\n",
    "                    size=image.shape[:2],\n",
    "                    mode=\"bicubic\",\n",
    "                    align_corners=False,\n",
    "                ).squeeze()\n",
    "\n",
    "            prediction: ndarray = prediction.cpu().numpy()\n",
    "\n",
    "            cv2.imwrite(outputPath, prediction)\n",
    "            bar.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     estimateDepth(imagePaths, depth_MiDaSsmall)\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn [14], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m depth_MiDaSsmall: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMiDaS_small\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mdir\u001b[39m: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mImage directory to analyze: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m imagePaths: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m readDirectory(\u001b[39mdir\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m estimateDepth(imagePaths, depth_DPTHybrid)\n\u001b[1;32m     10\u001b[0m estimateDepth(imagePaths, depth_DPTLarge)\n",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m, in \u001b[0;36mreadDirectory\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadDirectory\u001b[39m(\u001b[39mdir\u001b[39m: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     files: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m listdir(\u001b[39mdir\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m     filepaths: \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m [join(\u001b[39mdir\u001b[39m, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files]\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m filepaths\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    depth_DPTLarge: str = \"DPT_Large\"\n",
    "    depth_DPTHybrid: str = \"DPT_Hybrid\"\n",
    "    depth_MiDaSsmall: str = \"MiDaS_small\"\n",
    "\n",
    "    dir: str = input(\"Image directory to analyze: \")\n",
    "    imagePaths: list = readDirectory(dir)\n",
    "\n",
    "    estimateDepth(imagePaths, depth_DPTHybrid)\n",
    "    estimateDepth(imagePaths, depth_DPTLarge)\n",
    "    estimateDepth(imagePaths, depth_MiDaSsmall)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('saliency-mapper-VKvJKC8t-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d5897e754003be2867bdbeede15df27eea7dba2acc1117409fb09030001aea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
